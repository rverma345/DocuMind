# ğŸ§  DocuMind: Universal Document Intelligence Chatbot

DocuMind is an **AI-powered assistant** that can intelligently answer questions from your **uploaded documents** (PDFs) and perform **web searches** when required.  
It combines **LangChain, OpenAI, ChromaDB, and Streamlit** to deliver context-aware, source-backed responses.

---

## âœ¨ Features

- ğŸ“‚ **Document Ingestion** â€“ Upload multiple PDFs, split into chunks, and store embeddings in **ChromaDB**.  
- ğŸ” **Smart Query Routing** â€“ Decides whether to answer using:
  - **Document Search** (if high document relevance).  
  - **Web Search** (if query is external or recent).  
  - **Hybrid Search** (mix of both).  
- ğŸ¤– **LLM-Powered Answers** â€“ Uses OpenAIâ€™s GPT model to generate clear, concise answers.  
- ğŸ“Œ **Source Attribution** â€“ Always provides references from documents or web links.  
- ğŸ’¬ **Chat History** â€“ Maintains conversation context within the Streamlit app.  

---

## ğŸš€ Tech Stack

- [Streamlit](https://streamlit.io/) â€“ UI framework  
- [LangChain](https://www.langchain.com/) â€“ Orchestration  
- [OpenAI](https://openai.com/) â€“ LLM + Embeddings  
- [ChromaDB](https://www.trychroma.com/) â€“ Vector database for document search  
- [Serper API](https://serper.dev/) â€“ Google Search API  

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ app.py              # Main Streamlit app
â”œâ”€â”€ ingestion.py        # PDF ingestion, chunking & embedding
â”œâ”€â”€ search.py           # Document/Web/Hybrid search logic
â”œâ”€â”€ route.py            # Query router
â”œâ”€â”€ llm_results.py      # LLM response generator
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ README.md           # Project documentation
â”œâ”€â”€ .gitignore          # Ignore secrets & large files
â””â”€â”€ vector_store/       # Local ChromaDB (ignored in git)
```

---

## âš™ï¸ Installation & Setup

### 1. Clone the Repository
```bash
git clone https://github.com/your-username/DocuMind.git
cd DocuMind
```

### 2. Create Virtual Environment
```bash
python -m venv venv
source venv/bin/activate   # (Linux/Mac)
venv\Scripts\activate      # (Windows)
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Setup Environment Variables  
Create a `.env` file in the root folder:
```ini
OPENAI_API_KEY=your_openai_api_key
SERPER_API_KEY=your_serper_api_key
```

âš ï¸ Never commit `.env` to GitHub.  

---

## â–¶ï¸ Run the App
```bash
streamlit run app.py
```

Then open [http://localhost:8501](http://localhost:8501) in your browser.  

---

## ğŸ§ª Usage

1. Upload your PDFs from the sidebar.  
2. Click **Process** to embed them into ChromaDB.  
3. Ask questions in the chat box:  
   - *â€œSummarize the second chapter from my notes.â€*  
   - *â€œWhat are the latest AI trends in 2025?â€* (routes to web search).  
   - *â€œCompare CNN and RNN from my uploaded material.â€*  

---

## ğŸ›¡ï¸ Security

- API keys are stored in `.env`.  
- Uploaded PDFs and vector DB are ignored in Git.  
- Safe fallback: If no relevant context â†’ model replies *â€œI donâ€™t know.â€*  

